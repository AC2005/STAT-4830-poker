# Self Critique
# Observe
- Notebook is well organized into different parts, and everything is combined into a single notebook
- There are a lot of different hyperparameters/variables that could be changed in the code, so some more comments detailing what should/shouldn't be touched would be good
# Orient
### Strengths
- Changes suggested from last week were achieved
- Graphs and evaluation methods were finally created, allowing us to demonstrate real results rather than intuition
### Areas for Improvement
- Next steps are rather vague, and it is not clear that they are easily achievable
- More validation methods against real human-like game play should be explored
- GitHub in general needs to be more organized
### Critical Risks/Assumption
- Assuming that the model is not facing collapse and only learning how to play against non-humans
- Assuming that this method of training LLMs in poker will scale and continue improving with larger models and more data
# Decide
### Concrete Next Actions
- Look for 6-player human-like bots that we can improve our model against, or figure out a method to play our model against real humans
- Organize GitHub repository by fixing names and getting rid of unnecessary files
- Provide more explanation of how our methodology of training differs from traditional GTO-trained bots
# Act
### Resource Needs
- Need to possibly pay for 6-player GTO bots
- Need to learn more about how to use agents to possibly play in online games to gain more data or a better evaluation method